{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8a66f23-1239-4e49-b9e9-274b87e0abb7",
   "metadata": {},
   "source": [
    "### Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?\n",
    "\n",
    "### Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n",
    "\n",
    "### Q3. How does Bernoulli Naive Bayes handle missing values?\n",
    "\n",
    "### Q4. Can Gaussian Naive Bayes be used for multi-class classification?\n",
    "\n",
    "### Q5. Assignment:\n",
    "**Data preparation:**\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message is spam or not based on several input features.\n",
    "\n",
    "**Implementation:**\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the dataset. You should use the default hyperparameters for each classifier.\n",
    "\n",
    "**Results:**\n",
    "Report the following performance metrics for each classifier:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "\n",
    "**Discussion:**\n",
    "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is the case? Are there any limitations of Naive Bayes that you observed?\n",
    "\n",
    "**Conclusion:**\n",
    "Summarise your findings and provide some suggestions for future work.\n",
    "\n",
    "**Note:** This dataset contains a binary classification problem with multiple features. The dataset is relatively small, but it can be used to demonstrate the performance of the different variants of Naive Bayes on a real-world problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acebc967-c43e-4d75-acd8-dda9b38f5848",
   "metadata": {},
   "source": [
    "# Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?\n",
    "\n",
    "This problem is an application of **Bayes' theorem**. The formula for Bayes' theorem is:\n",
    "\n",
    "\\[\n",
    "P(\\text{Smoker}|\\text{Uses Plan}) = \\frac{P(\\text{Uses Plan}|\\text{Smoker}) \\cdot P(\\text{Smoker})}{P(\\text{Uses Plan})}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( P(\\text{Uses Plan}) = 0.7 \\) (70% of employees use the plan)\n",
    "- \\( P(\\text{Smoker}|\\text{Uses Plan}) = 0.4 \\) (40% of plan users are smokers)\n",
    "- \\( P(\\text{Smoker}) \\) is the prior probability that an employee is a smoker, which can be derived from the given data.\n",
    "\n",
    "### To calculate:\n",
    "1. \\( P(\\text{Uses Plan}|\\text{Smoker}) = P(\\text{Smoker}|\\text{Uses Plan}) \\cdot P(\\text{Uses Plan}) \\)\n",
    "2. Use Bayes' theorem to find \\( P(\\text{Smoker}|\\text{Uses Plan}) \\).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b23b7a-4f8e-4ee1-a6c8-4816b186c869",
   "metadata": {},
   "source": [
    "# Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n",
    "\n",
    "**Bernoulli Naive Bayes** and **Multinomial Naive Bayes** are both variants of Naive Bayes but differ in how they treat feature data:\n",
    "\n",
    "- **Bernoulli Naive Bayes**: Assumes binary (0 or 1) features. It works well when the features represent the presence or absence of certain characteristics (e.g., word presence in spam detection).\n",
    "  \n",
    "- **Multinomial Naive Bayes**: Assumes features represent counts or frequencies of events (e.g., word counts in spam detection). Itâ€™s more suitable when the data is represented by frequency counts rather than binary features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7286617-c924-4780-83a4-a0b40ae8bd1d",
   "metadata": {},
   "source": [
    "# Q3. How does Bernoulli Naive Bayes handle missing values?\n",
    "\n",
    "**Bernoulli Naive Bayes** typically handles missing values by treating them as a separate class or by ignoring them in the model. However, handling missing values depends on how the missing data is encoded:\n",
    "- If missing values are treated as a separate category, they will be modeled as a distinct feature.\n",
    "- In other cases, preprocessing techniques such as imputation may be applied before training the model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa2bf8e-d279-4646-925a-3903f2389d83",
   "metadata": {},
   "source": [
    "# Q4. Can Gaussian Naive Bayes be used for multi-class classification?\n",
    "\n",
    "Yes, **Gaussian Naive Bayes** can be used for **multi-class classification**. It assumes that the features follow a Gaussian (normal) distribution and works for both binary and multi-class classification problems. In multi-class classification, it calculates the posterior probability for each class and assigns the class with the highest probability.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce35e02-44e3-437a-b957-aa12890f1b4c",
   "metadata": {},
   "source": [
    "# Q5. Assignment:\n",
    "\n",
    "### Data preparation:\n",
    "- **Download the \"Spambase Data Set\"** from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message is spam or not based on several input features.\n",
    "\n",
    "### Implementation:\n",
    "- Implement **Bernoulli Naive Bayes**, **Multinomial Naive Bayes**, and **Gaussian Naive Bayes** classifiers using the scikit-learn library in Python.\n",
    "- Use **10-fold cross-validation** to evaluate the performance of each classifier on the dataset.\n",
    "\n",
    "### Results:\n",
    "- Report the following performance metrics for each classifier:\n",
    "  - **Accuracy**: The proportion of correct predictions.\n",
    "  - **Precision**: The proportion of true positives out of all predicted positives.\n",
    "  - **Recall**: The proportion of true positives out of all actual positives.\n",
    "  - **F1 score**: The harmonic mean of precision and recall.\n",
    "\n",
    "### Discussion:\n",
    "- Discuss the results you obtained. \n",
    "  - Which variant of Naive Bayes performed the best? Why do you think that is the case?\n",
    "  - Are there any limitations of Naive Bayes that you observed?\n",
    "\n",
    "### Conclusion:\n",
    "- Summarize your findings and provide suggestions for future work.\n",
    "\n",
    "**Note**: This dataset contains a binary classification problem with multiple features. It is relatively small, but it can be used to demonstrate the performance of the different variants of Naive Bayes on a real-world problem.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
